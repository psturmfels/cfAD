{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression, make_classification, make_blobs\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "from CrossValidation import *\n",
    "from FeatureSimilarity import GetTopGenes\n",
    "from MatrixFactorization import CreateLatentVariables, FactorizeMatrix, GetRepresentationError\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "g = 1100\n",
    "o = 100\n",
    "k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta, lamb1, lamb2 = 0.053705, 0.013012, 0.007704\n",
    "eta_nn, lamb1_nn, lamb2_nn = 0.053890, 0.015103, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFtoDataset(df, scale=False):\n",
    "    X = df[[str(i) for i in np.arange(n)]].values.T\n",
    "    if (scale):\n",
    "        X = preprocessing.scale(X)\n",
    "    y_cls = df['gene_group'].values[o:].astype(np.int32)\n",
    "    binaryPathwayMatrix = np.zeros((g, k))\n",
    "    binaryPathwayMatrix[np.arange(o, g), y_cls] = 1\n",
    "    geneCoeffs = df[['coeff{}'.format(i) for i in range(o)]].values[o:, :]  \n",
    "\n",
    "    return X, binaryPathwayMatrix, geneCoeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFileBase = '/homes/gws/psturm/simulatedData/regressionData/df{}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataFileBase.format(0))\n",
    "X, binaryPathwayMatrix, geneCoeffs = DFtoDataset(df, scale=True)\n",
    "neighbors=GetNeighborDictionary(binaryPathwayMatrix)\n",
    "X_half = X[:, np.concatenate([range(0, int(o/2)), range(o, g)])]\n",
    "X_one = X[:, np.concatenate([[0], range(o, g)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numReps = 100\n",
    "intersectionGap = 1\n",
    "numPlotPoints = int((g-o) / intersectionGap)\n",
    "\n",
    "def TrainReps(rep, n, g, k, o):\n",
    "    #needs: n, g, k\n",
    "    print('{},'.format(rep), end='')\n",
    "\n",
    "    df = pd.read_csv(dataFileBase.format(rep))\n",
    "    X, binaryPathwayMatrix, geneCoeffs = DFtoDataset(df, scale=True)\n",
    "    pca = PCA(n_components=50)\n",
    "    projectedX = pca.fit_transform(X.T)\n",
    "    latent_dim = np.min(np.where(np.cumsum(pca.explained_variance_ratio_) > 0.95)[0])\n",
    "    \n",
    "    X_half = X[:, np.concatenate([range(0, int(o/2)), range(o, g)])]\n",
    "    X_one = X[:, np.concatenate([[0], range(o, g)])]\n",
    "    \n",
    "    neighbors = GetNeighborDictionary(binaryPathwayMatrix, percentileThreshold=95)\n",
    "    genesDrivingPhenotype = np.where(geneCoeffs[:, 0] != 0)[0]\n",
    "    \n",
    "    #Train on all of the data\n",
    "    U_pred_init, V_pred_init = CreateLatentVariables(n, g, latent_dim)\n",
    "    U_pred, V_pred           = FactorizeMatrix(X, U_pred_init, V_pred_init, neighbors, \n",
    "                                     eta=eta, lamb1=lamb1, lamb2=lamb2, num_epochs=10)\n",
    "    \n",
    "    U_pred_init, V_pred_init = CreateLatentVariables(n, g, latent_dim)\n",
    "    U_pred_half, V_pred_half = FactorizeMatrix(X_half, U_pred_init, V_pred_init, neighbors, \n",
    "                                     eta=eta, lamb1=lamb1, lamb2=lamb2, num_epochs=10)\n",
    "    \n",
    "    U_pred_init, V_pred_init = CreateLatentVariables(n, g, latent_dim)\n",
    "    U_pred_one, V_pred_one = FactorizeMatrix(X_one, U_pred_init, V_pred_init, neighbors, \n",
    "                                     eta=eta, lamb1=lamb1, lamb2=lamb2, num_epochs=10)\n",
    "    \n",
    "    U_pred_init, V_pred_init = CreateLatentVariables(n, g, latent_dim)\n",
    "    U_pred_nn, V_pred_nn     = FactorizeMatrix(X, U_pred_init, V_pred_init, {}, \n",
    "                                     eta=eta_nn, lamb1=lamb1_nn, lamb2=lamb2_nn, num_epochs=10)\n",
    "    \n",
    "    tg     = GetTopGenes(V_pred, 0, np.arange(o, g))\n",
    "    tg_half = GetTopGenes(V_pred_half, 0, np.arange(int(o/2), g))\n",
    "    tg_one  = GetTopGenes(V_pred_one, 0, np.arange(1, g))\n",
    "    tg_nn      = GetTopGenes(V_pred_nn, 0, np.arange(o, g))\n",
    "    tg_raw_cor = GetTopGenes(X.T, 0, np.arange(o, g), correlation=True)\n",
    "    \n",
    "    intersection_mat = np.zeros((5, numPlotPoints))\n",
    "    index = 0\n",
    "    for i in range(0, g - o, intersectionGap):\n",
    "        intersection_mat[0, index] = np.sum(np.in1d(tg[i:i+intersectionGap], genesDrivingPhenotype))\n",
    "        intersection_mat[1, index] = np.sum(np.in1d(tg_half[i:i+intersectionGap], genesDrivingPhenotype))\n",
    "        intersection_mat[2, index] = np.sum(np.in1d(tg_one[i:i+intersectionGap], genesDrivingPhenotype))\n",
    "        intersection_mat[3, index] = np.sum(np.in1d(tg_nn[i:i+intersectionGap], genesDrivingPhenotype))\n",
    "        intersection_mat[4, index] = np.sum(np.in1d(tg_raw_cor[i:i+intersectionGap], genesDrivingPhenotype))\n",
    "        \n",
    "        index += 1\n",
    "    \n",
    "    return intersection_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numProcesses = 20\n",
    "p = Pool(numProcesses)\n",
    "tg_zipped = p.map(partial(TrainReps, n=n, g=g, k=k, o=o), range(numReps))\n",
    "p.close()\n",
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tg_stacked = np.stack(tg_zipped, axis=0) #of shape numReps, 5, numPlotPoints\n",
    "tg_summed  = np.cumsum(tg_stacked, axis=2) #cumulative sum over numPlotPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dot  = tg_summed[:, 0, :]\n",
    "half_dot = tg_summed[:, 1, :]\n",
    "one_dot  = tg_summed[:, 2, :]\n",
    "nn_dot  = tg_summed[:, 3, :]\n",
    "raw_cor = tg_summed[:, 4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.arange(1, 801)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseSaveDir = 'DataFrames/mvRegression/{}'\n",
    "elastic_net_mat = pd.read_csv(baseSaveDir.format('elastic_net.csv')).values.T\n",
    "elastic_net_df  = MatToMeltDF(elastic_net_mat, group_name='elastic_net', x_values=x_values)\n",
    "\n",
    "sparse_gl_mat  = pd.read_csv(baseSaveDir.format('sparse_gl.csv')).values.T\n",
    "sparse_gl_df = MatToMeltDF(sparse_gl_mat, group_name='sparse_gl', x_values=x_values)\n",
    "\n",
    "overlap_gl_mat = pd.read_csv(baseSaveDir.format('overlap_gl.csv')).values.T\n",
    "overlap_gl_df = MatToMeltDF(overlap_gl_mat, group_name='overlap_gl', x_values=x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_dot_df  = MatToMeltDF(im_dot, group_name='MF_dot',   x_values=x_values)\n",
    "half_dot_df = MatToMeltDF(half_dot, group_name='half_dot', x_values=x_values)\n",
    "one_dot_df = MatToMeltDF(one_dot, group_name='one_dot', x_values=x_values)\n",
    "nn_dot_df  = MatToMeltDF(nn_dot, group_name='nn_dot',   x_values=x_values)\n",
    "raw_cor_df = MatToMeltDF(raw_cor, group_name='raw_cor', x_values=x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "sns.set(font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'im_dot_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-616ae30ea22b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mim_dot_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'im_dot_df' is not defined"
     ]
    }
   ],
   "source": [
    "im_dot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-47ce1415c41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sns.lineplot(x='num genes identified as significant', y='num identified actually significant', hue='group', \n\u001b[0m\u001b[1;32m      2\u001b[0m              data=pd.concat([im_dot_df, one_dot_df, half_dot_df, raw_cor_df]), ci=None)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.lineplot(x='num genes identified as significant', y='num identified actually significant', hue='group', \n",
    "             data=pd.concat([im_dot_df, one_dot_df, half_dot_df, raw_cor_df]), ci=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
